{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 3: Further Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. NYC buildings - Load and inspect a noisy dataset\n",
    "We are using the PLUTO (Primary Land Use Tax Lot Output) database, which lists every building in New York City.\n",
    "Source is [NYC Open Data Portal](https://www1.nyc.gov/site/planning/data-maps/open-data/dwn-pluto-mappluto.page). Check the [data dictionary](https://www1.nyc.gov/assets/planning/download/pdf/data-maps/open-data/pluto_datadictionary.pdf?r=18v2beta)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as plt\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe using read_csv()\n",
    "\n",
    "url = 'https://github.com/worldbank/Python-for-Data-Science/raw/master/Spring%202019%208-week%20course/week%203/pluto_shorter.csv'\n",
    "\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how big is it?\n",
    "\n",
    "df.shape    # bonus: can you print 'loaded dataset with x rows and y columns'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect with .head()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Clean up the dataset\n",
    "Also known as 'data munging'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List the columns\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of desired columns; discard the rest.\n",
    "\n",
    "my_cols = ['borough','numfloors','yearbuilt', 'landuse', 'zipcode', 'unitstotal', 'assesstot','policeprct']\n",
    "df = df[my_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isnull() checks for missing values\n",
    "\n",
    "df.borough.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# what data structure would be helpful to rename columns? (think 'old_name' : 'new_name')\n",
    "\n",
    "df.rename(columns = {'zipcode': 'zip', 'yearbuilt': 'year_built', 'unitstotal': 'housing_units', 'assesstotal': 'assessed_value_USD'},\n",
    "         inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each Series has a data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memo: `police_precint` would be better as an int."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Exploratory visualization\n",
    "Pandas allows quick, iterative plotting to explore the properties of your data - helpful to diagnose data quality issues.\n",
    "\n",
    "A histogram plots the frequency of each unique value. Let's plot one for year_built. Any problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .hist() plots a histogram for all values in a Series.\n",
    "\n",
    "df.year_built.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pause to get help on the .hist() method\n",
    "\n",
    "df.hist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Presumably few NYC buildings were constructed during the early days of the Roman Empire.\n",
    "# Set year_built to np.nan for such values.\n",
    "\n",
    "df.year_built[df.year_built < 1000] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram should make sense without the erroneous values\n",
    "\n",
    "df.year_built.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Handle missing values\n",
    "How many missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isnull() evaluates each item, returning True if NaN and False otherwise\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " What steps to take, eg:\n",
    "* drop rows with missing values\n",
    "* deduce the missing values (eg. ZIP from coordinates)\n",
    "* fill NaNs using mean, median or a custom strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find methods to address missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how a method works and what parameters it needs\n",
    "\n",
    "df.fillna?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, drop all rows with NaNs\n",
    "\n",
    "print('original shape: ', df.shape)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "print('new shape: ', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Compute summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use methods like max, min and mean() on a column\n",
    "\n",
    "print(\"Max floors: \", df.numfloors.max())\n",
    "print(\"Mean assessed value: {:.0f}\".format(df.assesstot.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use plotting to explore relationships in the data\n",
    "\n",
    "df.plot(x = 'year_built', y = 'numfloors', kind = 'scatter', title = 'NYC buildings: Year built versus number of floors',figsize = (10,6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second example - unemployment data\n",
    "*Objectives: Merge datasets, fill missing data through interpolation, use time series*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a dataset of Eurostat unemployment data \n",
    "\n",
    "unemployment = pd.read_csv('https://raw.githubusercontent.com/worldbank/Python-for-Data-Science/master/Spring%202019%208-week%20course/week%205/data/country_total.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect with the .head() method\n",
    "\n",
    "unemployment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the .shape attribute gives a tuple with row and column numbers\n",
    "\n",
    "unemployment.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that the month column actually shows the year and month. Let's rename it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass a dictionary to the .rename() method, specifying the column to rename (the dictionary key) and the new name to use (the dictionary value).\n",
    "\n",
    "unemployment.rename(columns = {'month': 'year_month'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data munging**\n",
    "\n",
    "This column is not easy to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment['year_month'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's separate year and month into their own columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step by step: first make the column contain strings\n",
    "\n",
    "unemployment.year_month = unemployment.year_month.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check what an example cell looks like\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is this code structure called? Practice it as homework.\n",
    "\n",
    "[string.split('.')[0] for string in unemployment.year_month][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reassign to new column\n",
    "\n",
    "unemployment['year'] = [string.split('.')[0] for string in unemployment.year_month]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment['month'] = [string.split('.')[1] for string in unemployment.year_month]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be better to see the full names of the countries. Let's load another csv that has these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_url = 'https://raw.githubusercontent.com/dlab-berkeley/introduction-to-pandas/master/data/countries.csv'\n",
    "countries = pd.read_csv(countries_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merging dataframes**\n",
    "\n",
    "Now, let's merge the two dfs, to get full country name and country_group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_names = countries[['country','name_en','country_group']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment = pd.merge(unemployment, country_names, on='country')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the full [documentation](http://pandas.pydata.org/pandas-docs/stable/merging.html#database-style-dataframe-joining-merging) on merging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Value counts and sorting**\n",
    "\n",
    "What's the state of unemployment data for these countries? Do some countries report more frequently?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these options mean not seasonally adjusted, seasonally adjusted, trend cycle\n",
    "\n",
    "unemployment.seasonality.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .value_counts() return a Series containing unique values as its index and\n",
    "# frequencies as its values, in descending order.\n",
    "\n",
    "unemployment.name_en.value_counts().sort_values(ascending = True)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset runs from {} to {}\".format(unemployment.year.min(), unemployment.year.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**View subsets of the data based on conditions**\n",
    "\n",
    "You can subset the data using the syntax below.\n",
    "\n",
    "For now, just learn and adapt this syntax. As homework, look up Boolean indexing in the McKinney book and see why this works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment[unemployment.name_en == 'Italy'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment[unemployment.unemployment_rate < 10].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarize values with `groupby()`\n",
    "A `groupby()` operation carries out some combination of splitting the data, performing an operation, and combining the results:\n",
    "\n",
    "* state the Series you want to group by.\n",
    "* append the operation you want to perform such as .mean(), .sum() or .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_small = unemployment[['unemployment_rate','name_en']]\n",
    "\n",
    "unemployment_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_small.groupby('name_en',sort=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_small.groupby('name_en',sort=True).mean().sort_values(by = 'unemployment_rate', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop or fill missing values**\n",
    "\n",
    "It's not surprising that different statistical agencies collect unemployment stats at different frequencies. But to compare say Spain and Portugal, we may wish to fill the missing value gaps. Pandas has several options, a simple one being ffill (forward fill)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at two neighbors with high unemployment: Latvia and Lithuania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add a datetime index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recombine the year and month columns\n",
    "\n",
    "unemployment['year_month'] = unemployment['year'] + \":\"+ unemployment['month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify a format to parse datetimes, based on these: %d/%m/%Y”\n",
    "\n",
    "unemployment['date_time'] = pd.to_datetime(unemployment.year_month, format='%Y:%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make it the df's index\n",
    "\n",
    "unemployment.set_index('date_time',drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = parse('1995-01-01')\n",
    "end_date = parse('2000-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment[unemployment.index > start_date][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize = (8,5))\n",
    "\n",
    "unemployment.unemployment_rate[unemployment.name_en == 'Latvia'].plot(ax = ax)\n",
    "unemployment.unemployment_rate[unemployment.name_en == 'Lithuania'].plot(ax = ax)\n",
    "\n",
    "ax.set(title=\"Unemployment: Lithuania and Latvia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
